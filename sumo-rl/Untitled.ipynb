{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import sumo_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-07 19:06:57,466\tINFO services.py:1171 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\gym-0.18.0-py3.8.egg\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-02-07 19:07:06,367\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-02-07 19:07:06,367\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\gym-0.18.0-py3.8.egg\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\gym-0.18.0-py3.8.egg\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Step #0.00 (0ms ?*RT. ?UPS, TraCI: 19ms, vehicles TOT 0 ACT 0 BUF 0)                     \r",
      "\r\n",
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m Step #0.00 (0ms ?*RT. ?UPS, TraCI: 19ms, vehicles TOT 0 ACT 0 BUF 0)                     \r",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m 2021-02-07 19:07:13,009\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "2021-02-07 19:07:14,266\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\rllib\\policy\\tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 10, 'timers': {'grad_wait_time_ms': 96.574, 'apply_grad_time_ms': 62.832, 'apply_grad_throughput': 159.154, 'update_time_ms': 2.991}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -1.5227706, 'policy_entropy': 54.06537, 'var_gnorm': 22.627424, 'vf_loss': 0.22204408, 'model': {}, 'grad_gnorm': 6.676024, 'vf_explained_var': 0.000554502}}, 'num_steps_sampled': 10, 'num_steps_trained': 10}, 'done': False, 'episodes_total': 0, 'training_iteration': 1, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-14', 'timestamp': 1612721234, 'time_this_iter_s': 0.1795198917388916, 'time_total_s': 0.1795198917388916, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 0.1795198917388916, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 34.0, 'ram_util_percent': 75.9}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\rllib\\policy\\tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n",
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m Instructions for updating:\r\n",
      "\u001b[2m\u001b[36m(pid=3600)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\r\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\rllib\\policy\\tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Instructions for updating:\r\n",
      "\u001b[2m\u001b[36m(pid=7180)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 230, 'timers': {'grad_wait_time_ms': 279.116, 'apply_grad_time_ms': 1.995, 'apply_grad_throughput': 5013.332, 'update_time_ms': 2.394}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -1.4845018, 'policy_entropy': 8.095461, 'var_gnorm': 22.774654, 'vf_loss': 1.1914164, 'model': {}, 'grad_gnorm': 10.854793, 'vf_explained_var': -0.08101654}}, 'num_steps_sampled': 230, 'num_steps_trained': 230}, 'done': False, 'episodes_total': 0, 'training_iteration': 2, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-20', 'timestamp': 1612721240, 'time_this_iter_s': 5.59703516960144, 'time_total_s': 5.776555061340332, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 5.776555061340332, 'timesteps_since_restore': 0, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 53.875, 'ram_util_percent': 76.0375}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 380, 'timers': {'grad_wait_time_ms': 312.156, 'apply_grad_time_ms': 2.493, 'apply_grad_throughput': 4010.809, 'update_time_ms': 2.194}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.22664803, 'policy_entropy': 4.261272, 'var_gnorm': 22.925585, 'vf_loss': 3.6403918, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 380, 'num_steps_trained': 380}, 'done': False, 'episodes_total': 0, 'training_iteration': 3, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-25', 'timestamp': 1612721245, 'time_this_iter_s': 5.163195371627808, 'time_total_s': 10.93975043296814, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 10.93975043296814, 'timesteps_since_restore': 0, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 49.82857142857143, 'ram_util_percent': 76.11428571428573}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 530, 'timers': {'grad_wait_time_ms': 343.599, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.411, 'update_time_ms': 2.194}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -1.5259886, 'policy_entropy': 9.414801, 'var_gnorm': 22.95694, 'vf_loss': 0.8115928, 'model': {}, 'grad_gnorm': 11.728649, 'vf_explained_var': 0.055232167}}, 'num_steps_sampled': 530, 'num_steps_trained': 530}, 'done': False, 'episodes_total': 0, 'training_iteration': 4, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-30', 'timestamp': 1612721250, 'time_this_iter_s': 4.9707255363464355, 'time_total_s': 15.910475969314575, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 15.910475969314575, 'timesteps_since_restore': 0, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 48.628571428571426, 'ram_util_percent': 76.12857142857145}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 680, 'timers': {'grad_wait_time_ms': 342.75, 'apply_grad_time_ms': 1.792, 'apply_grad_throughput': 5579.684, 'update_time_ms': 2.195}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 2.6070757, 'policy_entropy': 0.8771199, 'var_gnorm': 23.024027, 'vf_loss': 11.767009, 'model': {}, 'grad_gnorm': 40.000008, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 680, 'num_steps_trained': 680}, 'done': False, 'episodes_total': 0, 'training_iteration': 5, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-35', 'timestamp': 1612721255, 'time_this_iter_s': 5.305812835693359, 'time_total_s': 21.216288805007935, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 21.216288805007935, 'timesteps_since_restore': 0, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 47.525, 'ram_util_percent': 76.07499999999999}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 840, 'timers': {'grad_wait_time_ms': 337.159, 'apply_grad_time_ms': 2.493, 'apply_grad_throughput': 4011.385, 'update_time_ms': 2.593}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.54815805, 'policy_entropy': 3.7418492, 'var_gnorm': 23.086632, 'vf_loss': 10.512073, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 840, 'num_steps_trained': 840}, 'done': False, 'episodes_total': 0, 'training_iteration': 6, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-40', 'timestamp': 1612721260, 'time_this_iter_s': 5.413524866104126, 'time_total_s': 26.62981367111206, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 26.62981367111206, 'timesteps_since_restore': 0, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 55.871428571428574, 'ram_util_percent': 76.07142857142857}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1000, 'timers': {'grad_wait_time_ms': 340.724, 'apply_grad_time_ms': 1.894, 'apply_grad_throughput': 5278.776, 'update_time_ms': 2.394}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.05163604, 'policy_entropy': 0.38181305, 'var_gnorm': 23.100588, 'vf_loss': 12.778699, 'model': {}, 'grad_gnorm': 39.999996, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1000, 'num_steps_trained': 1000}, 'done': False, 'episodes_total': 0, 'training_iteration': 7, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-46', 'timestamp': 1612721266, 'time_this_iter_s': 5.504282712936401, 'time_total_s': 32.13409638404846, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 32.13409638404846, 'timesteps_since_restore': 0, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 50.9625, 'ram_util_percent': 76.1}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1140, 'timers': {'grad_wait_time_ms': 364.454, 'apply_grad_time_ms': 2.194, 'apply_grad_throughput': 4558.481, 'update_time_ms': 2.394}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.059047014, 'policy_entropy': 0.71805716, 'var_gnorm': 23.062164, 'vf_loss': 6.151826, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1140, 'num_steps_trained': 1140}, 'done': False, 'episodes_total': 0, 'training_iteration': 8, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-51', 'timestamp': 1612721271, 'time_this_iter_s': 5.1203086376190186, 'time_total_s': 37.25440502166748, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 37.25440502166748, 'timesteps_since_restore': 0, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 64.18571428571428, 'ram_util_percent': 76.35714285714286}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1280, 'timers': {'grad_wait_time_ms': 380.672, 'apply_grad_time_ms': 2.194, 'apply_grad_throughput': 4558.283, 'update_time_ms': 2.693}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.91798466, 'policy_entropy': 1.0125753, 'var_gnorm': 23.02228, 'vf_loss': 0.72446966, 'model': {}, 'grad_gnorm': 22.035414, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1280, 'num_steps_trained': 1280}, 'done': False, 'episodes_total': 0, 'training_iteration': 9, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-07-56', 'timestamp': 1612721276, 'time_this_iter_s': 5.333765983581543, 'time_total_s': 42.58817100524902, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 42.58817100524902, 'timesteps_since_restore': 0, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 51.95, 'ram_util_percent': 76.225}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1420, 'timers': {'grad_wait_time_ms': 380.656, 'apply_grad_time_ms': 2.194, 'apply_grad_throughput': 4558.134, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -5.359602, 'policy_entropy': 3.3363006, 'var_gnorm': 22.991179, 'vf_loss': 0.8489068, 'model': {}, 'grad_gnorm': 18.783007, 'vf_explained_var': -0.65596294}}, 'num_steps_sampled': 1420, 'num_steps_trained': 1420}, 'done': False, 'episodes_total': 0, 'training_iteration': 10, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-02', 'timestamp': 1612721282, 'time_this_iter_s': 5.38161039352417, 'time_total_s': 47.96978139877319, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 47.96978139877319, 'timesteps_since_restore': 0, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 51.02857142857143, 'ram_util_percent': 76.08571428571429}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1560, 'timers': {'grad_wait_time_ms': 413.074, 'apply_grad_time_ms': 1.795, 'apply_grad_throughput': 5571.161, 'update_time_ms': 2.493}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.015207184, 'policy_entropy': 1.3821396, 'var_gnorm': 23.011253, 'vf_loss': 2.3218336, 'model': {}, 'grad_gnorm': 28.99401, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1560, 'num_steps_trained': 1560}, 'done': False, 'episodes_total': 0, 'training_iteration': 11, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-08', 'timestamp': 1612721288, 'time_this_iter_s': 5.740679979324341, 'time_total_s': 53.710461378097534, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 53.710461378097534, 'timesteps_since_restore': 0, 'iterations_since_restore': 11, 'perf': {'cpu_util_percent': 49.0, 'ram_util_percent': 76.12222222222222}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1700, 'timers': {'grad_wait_time_ms': 401.818, 'apply_grad_time_ms': 2.094, 'apply_grad_throughput': 4775.371, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.011918511, 'policy_entropy': 0.78416264, 'var_gnorm': 23.05574, 'vf_loss': 2.7316508, 'model': {}, 'grad_gnorm': 36.148174, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1700, 'num_steps_trained': 1700}, 'done': False, 'episodes_total': 0, 'training_iteration': 12, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-13', 'timestamp': 1612721293, 'time_this_iter_s': 5.669652700424194, 'time_total_s': 59.38011407852173, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 59.38011407852173, 'timesteps_since_restore': 0, 'iterations_since_restore': 12, 'perf': {'cpu_util_percent': 56.8125, 'ram_util_percent': 76.15}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1830, 'timers': {'grad_wait_time_ms': 406.316, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5015.01, 'update_time_ms': 2.394}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.004760648, 'policy_entropy': 0.43449768, 'var_gnorm': 23.057688, 'vf_loss': 0.97794193, 'model': {}, 'grad_gnorm': 21.687471, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1830, 'num_steps_trained': 1830}, 'done': False, 'episodes_total': 0, 'training_iteration': 13, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-18', 'timestamp': 1612721298, 'time_this_iter_s': 5.1422505378723145, 'time_total_s': 64.52236461639404, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 64.52236461639404, 'timesteps_since_restore': 0, 'iterations_since_restore': 13, 'perf': {'cpu_util_percent': 48.60000000000001, 'ram_util_percent': 75.97142857142858}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1950, 'timers': {'grad_wait_time_ms': 424.271, 'apply_grad_time_ms': 1.995, 'apply_grad_throughput': 5013.692, 'update_time_ms': 2.296}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.2887008, 'policy_entropy': 2.2199557, 'var_gnorm': 23.05473, 'vf_loss': 0.27628064, 'model': {}, 'grad_gnorm': 9.985054, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1950, 'num_steps_trained': 1950}, 'done': False, 'episodes_total': 0, 'training_iteration': 14, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-24', 'timestamp': 1612721304, 'time_this_iter_s': 5.124297857284546, 'time_total_s': 69.64666247367859, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 69.64666247367859, 'timesteps_since_restore': 0, 'iterations_since_restore': 14, 'perf': {'cpu_util_percent': 54.61428571428571, 'ram_util_percent': 75.9}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2060, 'timers': {'grad_wait_time_ms': 422.115, 'apply_grad_time_ms': 1.593, 'apply_grad_throughput': 6276.831, 'update_time_ms': 2.195}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.1880142, 'policy_entropy': 3.9179296, 'var_gnorm': 23.069334, 'vf_loss': 2.1055417, 'model': {}, 'grad_gnorm': 31.180353, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 2060, 'num_steps_trained': 2060}, 'done': False, 'episodes_total': 0, 'training_iteration': 15, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-29', 'timestamp': 1612721309, 'time_this_iter_s': 5.392581462860107, 'time_total_s': 75.0392439365387, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 75.0392439365387, 'timesteps_since_restore': 0, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 49.2375, 'ram_util_percent': 76.025}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2170, 'timers': {'grad_wait_time_ms': 393.97, 'apply_grad_time_ms': 2.692, 'apply_grad_throughput': 3714.633, 'update_time_ms': 2.893}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 5.255046e-06, 'policy_entropy': 0.48743635, 'var_gnorm': 23.059746, 'vf_loss': 0.3450391, 'model': {}, 'grad_gnorm': 5.6105905, 'vf_explained_var': -0.14546216}}, 'num_steps_sampled': 2170, 'num_steps_trained': 2170}, 'done': False, 'episodes_total': 0, 'training_iteration': 16, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-34', 'timestamp': 1612721314, 'time_this_iter_s': 4.97170615196228, 'time_total_s': 80.01095008850098, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 80.01095008850098, 'timesteps_since_restore': 0, 'iterations_since_restore': 16, 'perf': {'cpu_util_percent': 55.05714285714286, 'ram_util_percent': 76.24285714285713}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2270, 'timers': {'grad_wait_time_ms': 426.562, 'apply_grad_time_ms': 4.388, 'apply_grad_throughput': 2279.055, 'update_time_ms': 3.391}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.008009346, 'policy_entropy': 0.38745528, 'var_gnorm': 23.058397, 'vf_loss': 1.5518374, 'model': {}, 'grad_gnorm': 25.711285, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 2270, 'num_steps_trained': 2270}, 'done': False, 'episodes_total': 0, 'training_iteration': 17, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-39', 'timestamp': 1612721319, 'time_this_iter_s': 5.282914400100708, 'time_total_s': 85.29386448860168, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 85.29386448860168, 'timesteps_since_restore': 0, 'iterations_since_restore': 17, 'perf': {'cpu_util_percent': 64.31428571428572, 'ram_util_percent': 76.37142857142858}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2370, 'timers': {'grad_wait_time_ms': 416.96, 'apply_grad_time_ms': 1.995, 'apply_grad_throughput': 5013.692, 'update_time_ms': 2.094}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -1.4623916, 'policy_entropy': 0.67595655, 'var_gnorm': 23.050194, 'vf_loss': 0.31187057, 'model': {}, 'grad_gnorm': 10.425758, 'vf_explained_var': -0.34550953}}, 'num_steps_sampled': 2370, 'num_steps_trained': 2370}, 'done': False, 'episodes_total': 0, 'training_iteration': 18, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-44', 'timestamp': 1612721324, 'time_this_iter_s': 5.126294136047363, 'time_total_s': 90.42015862464905, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 90.42015862464905, 'timesteps_since_restore': 0, 'iterations_since_restore': 18, 'perf': {'cpu_util_percent': 55.7375, 'ram_util_percent': 76.95}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2480, 'timers': {'grad_wait_time_ms': 429.165, 'apply_grad_time_ms': 1.995, 'apply_grad_throughput': 5013.752, 'update_time_ms': 1.993}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.025078166, 'policy_entropy': 0.52675164, 'var_gnorm': 23.045074, 'vf_loss': 1.0156248, 'model': {}, 'grad_gnorm': 17.40815, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 2480, 'num_steps_trained': 2480}, 'done': False, 'episodes_total': 0, 'training_iteration': 19, 'experiment_id': '80410aa062cc4e95a2ffeb87269367dc', 'date': '2021-02-07_19-08-50', 'timestamp': 1612721330, 'time_this_iter_s': 5.2399890422821045, 'time_total_s': 95.66014766693115, 'pid': 5480, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000253A509A160>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 95.66014766693115, 'timesteps_since_restore': 0, 'iterations_since_restore': 19, 'perf': {'cpu_util_percent': 50.671428571428564, 'ram_util_percent': 77.01428571428572}}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray.rllib.agents.a3c.a3c import A3CTrainer\n",
    "from ray.rllib.agents.a3c.a3c_tf_policy import A3CTFPolicy\n",
    "from ray.tune.registry import register_env\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from sumo_rl import SumoEnvironment\n",
    "import traci\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ray.init()\n",
    "\n",
    "    register_env(\"4x4grid\", lambda _: SumoEnvironment(net_file='nets/4x4-Lucas/4x4.net.xml',\n",
    "                                                    route_file='nets/4x4-Lucas/4x4c1c2c1c2.rou.xml',\n",
    "                                                    out_csv_name='outputs/4x4grid/a3c',\n",
    "                                                    use_gui=False,\n",
    "                                                    num_seconds=80000,\n",
    "                                                    max_depart_delay=0))\n",
    "\n",
    "    trainer = A3CTrainer(env=\"4x4grid\", config={\n",
    "        \"multiagent\": {\n",
    "            \"policies\": {\n",
    "                '0': (A3CTFPolicy, spaces.Box(low=np.zeros(10), high=np.ones(10)), spaces.Discrete(2), {})\n",
    "            },\n",
    "            \"policy_mapping_fn\": (lambda id: '0')  # Traffic lights are always controlled by this policy\n",
    "        },\n",
    "        \"lr\": 0.001,\n",
    "        \"no_done_at_end\": True\n",
    "    })\n",
    "    while True:\n",
    "        print(trainer.train())  # distributed training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
