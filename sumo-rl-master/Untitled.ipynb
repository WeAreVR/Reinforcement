{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import sumo_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-07 18:57:21,584\tINFO services.py:1171 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\gym-0.18.0-py3.8.egg\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2021-02-07 18:57:32,185\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2021-02-07 18:57:32,186\tINFO trainer.py:616 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m Instructions for updating:\n",
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m non-resource variables are not supported in the long term\n",
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\gym-0.18.0-py3.8.egg\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\gym-0.18.0-py3.8.egg\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m Step #0.00 (0ms ?*RT. ?UPS, TraCI: 19ms, vehicles TOT 0 ACT 0 BUF 0)                     \r",
      "\r\n",
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m Step #0.00 (0ms ?*RT. ?UPS, TraCI: 22ms, vehicles TOT 0 ACT 0 BUF 0)                     \r",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m 2021-02-07 18:57:40,254\tWARNING deprecation.py:29 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
      "2021-02-07 18:57:41,577\tWARNING util.py:43 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\rllib\\policy\\tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 10, 'timers': {'grad_wait_time_ms': 116.981, 'apply_grad_time_ms': 73.802, 'apply_grad_throughput': 135.498, 'update_time_ms': 2.992}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -2.295218, 'policy_entropy': 58.224075, 'var_gnorm': 22.627424, 'vf_loss': 0.24924658, 'model': {}, 'grad_gnorm': 6.673241, 'vf_explained_var': -0.008594632}}, 'num_steps_sampled': 10, 'num_steps_trained': 10}, 'done': False, 'episodes_total': 0, 'training_iteration': 1, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-57-41', 'timestamp': 1612720661, 'time_this_iter_s': 0.24733877182006836, 'time_total_s': 0.24733877182006836, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 0.24733877182006836, 'timesteps_since_restore': 0, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 25.6, 'ram_util_percent': 75.7}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\rllib\\policy\\tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n",
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m Instructions for updating:\r\n",
      "\u001b[2m\u001b[36m(pid=11300)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\r\n",
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m WARNING:tensorflow:From C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\rllib\\policy\\tf_policy.py:850: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n",
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m Instructions for updating:\r\n",
      "\u001b[2m\u001b[36m(pid=13064)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 220, 'timers': {'grad_wait_time_ms': 277.033, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5277.713, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -1.7078204, 'policy_entropy': 16.535791, 'var_gnorm': 22.725092, 'vf_loss': 2.0286252, 'model': {}, 'grad_gnorm': 5.5707173, 'vf_explained_var': -0.047139168}}, 'num_steps_sampled': 220, 'num_steps_trained': 220}, 'done': False, 'episodes_total': 0, 'training_iteration': 2, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-57-47', 'timestamp': 1612720667, 'time_this_iter_s': 5.778568744659424, 'time_total_s': 6.025907516479492, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 6.025907516479492, 'timesteps_since_restore': 0, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 59.837500000000006, 'ram_util_percent': 75.175}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 400, 'timers': {'grad_wait_time_ms': 293.922, 'apply_grad_time_ms': 2.194, 'apply_grad_throughput': 4558.63, 'update_time_ms': 2.194}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 4.6184444, 'policy_entropy': 11.963565, 'var_gnorm': 22.898125, 'vf_loss': 7.314539, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': -0.34684432}}, 'num_steps_sampled': 400, 'num_steps_trained': 400}, 'done': False, 'episodes_total': 0, 'training_iteration': 3, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-57-53', 'timestamp': 1612720673, 'time_this_iter_s': 5.388591766357422, 'time_total_s': 11.414499282836914, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 11.414499282836914, 'timesteps_since_restore': 0, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 55.375, 'ram_util_percent': 75.1}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 550, 'timers': {'grad_wait_time_ms': 341.921, 'apply_grad_time_ms': 2.094, 'apply_grad_throughput': 4775.317, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.48003688, 'policy_entropy': 3.3339114, 'var_gnorm': 23.000086, 'vf_loss': 12.801773, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': -0.91472673}}, 'num_steps_sampled': 550, 'num_steps_trained': 550}, 'done': False, 'episodes_total': 0, 'training_iteration': 4, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-57-58', 'timestamp': 1612720678, 'time_this_iter_s': 5.111332893371582, 'time_total_s': 16.525832176208496, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 16.525832176208496, 'timesteps_since_restore': 0, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 53.91428571428571, 'ram_util_percent': 75.05714285714285}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 690, 'timers': {'grad_wait_time_ms': 366.782, 'apply_grad_time_ms': 2.094, 'apply_grad_throughput': 4775.643, 'update_time_ms': 2.494}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.9793554, 'policy_entropy': 5.223213, 'var_gnorm': 23.018238, 'vf_loss': 7.081124, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 690, 'num_steps_trained': 690}, 'done': False, 'episodes_total': 0, 'training_iteration': 5, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-03', 'timestamp': 1612720683, 'time_this_iter_s': 5.190791845321655, 'time_total_s': 21.71662402153015, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 21.71662402153015, 'timesteps_since_restore': 0, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 48.67142857142857, 'ram_util_percent': 74.97142857142856}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 830, 'timers': {'grad_wait_time_ms': 363.813, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5013.931, 'update_time_ms': 2.394}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 2.1162753, 'policy_entropy': 11.271885, 'var_gnorm': 23.020536, 'vf_loss': 7.59867, 'model': {}, 'grad_gnorm': 39.999996, 'vf_explained_var': -0.06585801}}, 'num_steps_sampled': 830, 'num_steps_trained': 830}, 'done': False, 'episodes_total': 0, 'training_iteration': 6, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-08', 'timestamp': 1612720688, 'time_this_iter_s': 5.257971286773682, 'time_total_s': 26.974595308303833, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 26.974595308303833, 'timesteps_since_restore': 0, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 50.6875, 'ram_util_percent': 74.95}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 980, 'timers': {'grad_wait_time_ms': 363.818, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.051, 'update_time_ms': 2.397}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.9981691, 'policy_entropy': 3.093479, 'var_gnorm': 23.120216, 'vf_loss': 7.346772, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': -0.18470645}}, 'num_steps_sampled': 980, 'num_steps_trained': 980}, 'done': False, 'episodes_total': 0, 'training_iteration': 7, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-13', 'timestamp': 1612720693, 'time_this_iter_s': 5.337726831436157, 'time_total_s': 32.31232213973999, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 32.31232213973999, 'timesteps_since_restore': 0, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 51.91428571428571, 'ram_util_percent': 74.97142857142856}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1130, 'timers': {'grad_wait_time_ms': 349.498, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5277.779, 'update_time_ms': 2.095}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 4.043804, 'policy_entropy': 7.378598, 'var_gnorm': 23.279123, 'vf_loss': 5.349102, 'model': {}, 'grad_gnorm': 40.000004, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1130, 'num_steps_trained': 1130}, 'done': False, 'episodes_total': 0, 'training_iteration': 8, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-19', 'timestamp': 1612720699, 'time_this_iter_s': 5.091386556625366, 'time_total_s': 37.403708696365356, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 37.403708696365356, 'timesteps_since_restore': 0, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 50.542857142857144, 'ram_util_percent': 74.94285714285715}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1270, 'timers': {'grad_wait_time_ms': 362.533, 'apply_grad_time_ms': 2.393, 'apply_grad_throughput': 4178.218, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.04748954, 'policy_entropy': 0.43865773, 'var_gnorm': 23.362661, 'vf_loss': 7.7264442, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1270, 'num_steps_trained': 1270}, 'done': False, 'episodes_total': 0, 'training_iteration': 9, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-24', 'timestamp': 1612720704, 'time_this_iter_s': 5.128288269042969, 'time_total_s': 42.531996965408325, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 42.531996965408325, 'timesteps_since_restore': 0, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 51.55, 'ram_util_percent': 74.9625}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1420, 'timers': {'grad_wait_time_ms': 408.148, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.411, 'update_time_ms': 2.793}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.0155319795, 'policy_entropy': 0.30636063, 'var_gnorm': 23.388689, 'vf_loss': 8.22148, 'model': {}, 'grad_gnorm': 40.000004, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1420, 'num_steps_trained': 1420}, 'done': False, 'episodes_total': 0, 'training_iteration': 10, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-29', 'timestamp': 1612720709, 'time_this_iter_s': 5.6548802852630615, 'time_total_s': 48.18687725067139, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 48.18687725067139, 'timesteps_since_restore': 0, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 52.475, 'ram_util_percent': 74.9}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1550, 'timers': {'grad_wait_time_ms': 425.7, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.291, 'update_time_ms': 2.394}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.0113731045, 'policy_entropy': 0.53544706, 'var_gnorm': 23.3737, 'vf_loss': 2.216336, 'model': {}, 'grad_gnorm': 29.448149, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1550, 'num_steps_trained': 1550}, 'done': False, 'episodes_total': 0, 'training_iteration': 11, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-35', 'timestamp': 1612720715, 'time_this_iter_s': 5.188127279281616, 'time_total_s': 53.375004529953, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 53.375004529953, 'timesteps_since_restore': 0, 'iterations_since_restore': 11, 'perf': {'cpu_util_percent': 55.128571428571426, 'ram_util_percent': 74.88571428571427}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1680, 'timers': {'grad_wait_time_ms': 431.471, 'apply_grad_time_ms': 1.695, 'apply_grad_throughput': 5898.664, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.0063666073, 'policy_entropy': 1.1583936, 'var_gnorm': 23.360237, 'vf_loss': 0.64523304, 'model': {}, 'grad_gnorm': 15.042104, 'vf_explained_var': -0.8471155}}, 'num_steps_sampled': 1680, 'num_steps_trained': 1680}, 'done': False, 'episodes_total': 0, 'training_iteration': 12, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-40', 'timestamp': 1612720720, 'time_this_iter_s': 5.258937835693359, 'time_total_s': 58.63394236564636, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 58.63394236564636, 'timesteps_since_restore': 0, 'iterations_since_restore': 12, 'perf': {'cpu_util_percent': 50.625, 'ram_util_percent': 74.8875}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1810, 'timers': {'grad_wait_time_ms': 406.865, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5277.248, 'update_time_ms': 2.194}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.22494128, 'policy_entropy': 1.5078933, 'var_gnorm': 23.345459, 'vf_loss': 3.0949492, 'model': {}, 'grad_gnorm': 34.716072, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 1810, 'num_steps_trained': 1810}, 'done': False, 'episodes_total': 0, 'training_iteration': 13, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-45', 'timestamp': 1612720725, 'time_this_iter_s': 5.061466932296753, 'time_total_s': 63.695409297943115, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 63.695409297943115, 'timesteps_since_restore': 0, 'iterations_since_restore': 13, 'perf': {'cpu_util_percent': 45.528571428571425, 'ram_util_percent': 74.77142857142857}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 1940, 'timers': {'grad_wait_time_ms': 404.575, 'apply_grad_time_ms': 2.293, 'apply_grad_throughput': 4360.527, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.12539525, 'policy_entropy': 2.0292, 'var_gnorm': 23.34249, 'vf_loss': 0.10056189, 'model': {}, 'grad_gnorm': 6.0683203, 'vf_explained_var': 0.06441641}}, 'num_steps_sampled': 1940, 'num_steps_trained': 1940}, 'done': False, 'episodes_total': 0, 'training_iteration': 14, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-50', 'timestamp': 1612720730, 'time_this_iter_s': 5.168181419372559, 'time_total_s': 68.86359071731567, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 68.86359071731567, 'timesteps_since_restore': 0, 'iterations_since_restore': 14, 'perf': {'cpu_util_percent': 53.07142857142857, 'ram_util_percent': 74.97142857142858}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2060, 'timers': {'grad_wait_time_ms': 420.813, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.711, 'update_time_ms': 2.195}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.44433382, 'policy_entropy': 2.3371654, 'var_gnorm': 23.342644, 'vf_loss': 0.9863291, 'model': {}, 'grad_gnorm': 15.33579, 'vf_explained_var': -0.70992255}}, 'num_steps_sampled': 2060, 'num_steps_trained': 2060}, 'done': False, 'episodes_total': 0, 'training_iteration': 15, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-58-55', 'timestamp': 1612720735, 'time_this_iter_s': 5.019578456878662, 'time_total_s': 73.88316917419434, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 73.88316917419434, 'timesteps_since_restore': 0, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 44.82857142857143, 'ram_util_percent': 75.14285714285714}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2190, 'timers': {'grad_wait_time_ms': 433.508, 'apply_grad_time_ms': 1.795, 'apply_grad_throughput': 5571.235, 'update_time_ms': 2.494}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.02102328, 'policy_entropy': 1.2734096, 'var_gnorm': 23.32709, 'vf_loss': 0.6038358, 'model': {}, 'grad_gnorm': 13.525666, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 2190, 'num_steps_trained': 2190}, 'done': False, 'episodes_total': 0, 'training_iteration': 16, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-01', 'timestamp': 1612720741, 'time_this_iter_s': 5.637927770614624, 'time_total_s': 79.52109694480896, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 79.52109694480896, 'timesteps_since_restore': 0, 'iterations_since_restore': 16, 'perf': {'cpu_util_percent': 53.224999999999994, 'ram_util_percent': 75.9875}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2320, 'timers': {'grad_wait_time_ms': 447.473, 'apply_grad_time_ms': 1.892, 'apply_grad_throughput': 5286.027, 'update_time_ms': 2.095}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.027836476, 'policy_entropy': 2.0203505, 'var_gnorm': 23.320576, 'vf_loss': 0.2119655, 'model': {}, 'grad_gnorm': 5.890545, 'vf_explained_var': -0.27602422}}, 'num_steps_sampled': 2320, 'num_steps_trained': 2320}, 'done': False, 'episodes_total': 0, 'training_iteration': 17, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-07', 'timestamp': 1612720747, 'time_this_iter_s': 5.8564512729644775, 'time_total_s': 85.37754821777344, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 85.37754821777344, 'timesteps_since_restore': 0, 'iterations_since_restore': 17, 'perf': {'cpu_util_percent': 47.724999999999994, 'ram_util_percent': 75.30000000000001}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2440, 'timers': {'grad_wait_time_ms': 403.931, 'apply_grad_time_ms': 3.69, 'apply_grad_throughput': 2710.024, 'update_time_ms': 2.095}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.015465854, 'policy_entropy': 1.8015459, 'var_gnorm': 23.316734, 'vf_loss': 0.26215023, 'model': {}, 'grad_gnorm': 6.975496, 'vf_explained_var': -0.5967349}}, 'num_steps_sampled': 2440, 'num_steps_trained': 2440}, 'done': False, 'episodes_total': 0, 'training_iteration': 18, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-12', 'timestamp': 1612720752, 'time_this_iter_s': 4.98866081237793, 'time_total_s': 90.36620903015137, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 90.36620903015137, 'timesteps_since_restore': 0, 'iterations_since_restore': 18, 'perf': {'cpu_util_percent': 57.800000000000004, 'ram_util_percent': 75.27142857142857}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2550, 'timers': {'grad_wait_time_ms': 420.007, 'apply_grad_time_ms': 1.995, 'apply_grad_throughput': 5013.572, 'update_time_ms': 2.693}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.1926045, 'policy_entropy': 2.9228344, 'var_gnorm': 23.33142, 'vf_loss': 0.06813166, 'model': {}, 'grad_gnorm': 1.8943001, 'vf_explained_var': 0.1183238}}, 'num_steps_sampled': 2550, 'num_steps_trained': 2550}, 'done': False, 'episodes_total': 0, 'training_iteration': 19, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-17', 'timestamp': 1612720757, 'time_this_iter_s': 5.1043524742126465, 'time_total_s': 95.47056150436401, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 95.47056150436401, 'timesteps_since_restore': 0, 'iterations_since_restore': 19, 'perf': {'cpu_util_percent': 57.6, 'ram_util_percent': 75.4375}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2660, 'timers': {'grad_wait_time_ms': 435.329, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5013.811, 'update_time_ms': 2.596}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.6385793, 'policy_entropy': 4.138439, 'var_gnorm': 23.349054, 'vf_loss': 0.3754094, 'model': {}, 'grad_gnorm': 7.7532215, 'vf_explained_var': 0.03964144}}, 'num_steps_sampled': 2660, 'num_steps_trained': 2660}, 'done': False, 'episodes_total': 0, 'training_iteration': 20, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-22', 'timestamp': 1612720762, 'time_this_iter_s': 5.2549498081207275, 'time_total_s': 100.72551131248474, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 100.72551131248474, 'timesteps_since_restore': 0, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 55.0, 'ram_util_percent': 75.28571428571429}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2770, 'timers': {'grad_wait_time_ms': 433.115, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.351, 'update_time_ms': 2.494}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.38568917, 'policy_entropy': 2.0564673, 'var_gnorm': 23.359104, 'vf_loss': 0.19355002, 'model': {}, 'grad_gnorm': 2.445454, 'vf_explained_var': 0.11061537}}, 'num_steps_sampled': 2770, 'num_steps_trained': 2770}, 'done': False, 'episodes_total': 0, 'training_iteration': 21, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-27', 'timestamp': 1612720767, 'time_this_iter_s': 5.273897171020508, 'time_total_s': 105.99940848350525, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 105.99940848350525, 'timesteps_since_restore': 0, 'iterations_since_restore': 21, 'perf': {'cpu_util_percent': 51.125, 'ram_util_percent': 75.2}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2880, 'timers': {'grad_wait_time_ms': 421.356, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5278.111, 'update_time_ms': 2.285}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.18002433, 'policy_entropy': 3.7941635, 'var_gnorm': 23.365776, 'vf_loss': 0.31142944, 'model': {}, 'grad_gnorm': 6.033986, 'vf_explained_var': -0.0026329756}}, 'num_steps_sampled': 2880, 'num_steps_trained': 2880}, 'done': False, 'episodes_total': 0, 'training_iteration': 22, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-32', 'timestamp': 1612720772, 'time_this_iter_s': 5.215563058853149, 'time_total_s': 111.2149715423584, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 111.2149715423584, 'timesteps_since_restore': 0, 'iterations_since_restore': 22, 'perf': {'cpu_util_percent': 53.62857142857143, 'ram_util_percent': 75.28571428571429}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 2980, 'timers': {'grad_wait_time_ms': 423.848, 'apply_grad_time_ms': 3.191, 'apply_grad_throughput': 3133.656, 'update_time_ms': 2.892}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.25907862, 'policy_entropy': 3.4894958, 'var_gnorm': 23.383223, 'vf_loss': 0.23547484, 'model': {}, 'grad_gnorm': 6.764283, 'vf_explained_var': -0.0053087473}}, 'num_steps_sampled': 2980, 'num_steps_trained': 2980}, 'done': False, 'episodes_total': 0, 'training_iteration': 23, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-38', 'timestamp': 1612720778, 'time_this_iter_s': 5.379086971282959, 'time_total_s': 116.59405851364136, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 116.59405851364136, 'timesteps_since_restore': 0, 'iterations_since_restore': 23, 'perf': {'cpu_util_percent': 61.3625, 'ram_util_percent': 75.45}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3080, 'timers': {'grad_wait_time_ms': 440.206, 'apply_grad_time_ms': 2.393, 'apply_grad_throughput': 4178.01, 'update_time_ms': 3.192}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.23854397, 'policy_entropy': 4.6841955, 'var_gnorm': 23.402916, 'vf_loss': 1.1057299, 'model': {}, 'grad_gnorm': 9.960792, 'vf_explained_var': 0.13073218}}, 'num_steps_sampled': 3080, 'num_steps_trained': 3080}, 'done': False, 'episodes_total': 0, 'training_iteration': 24, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-43', 'timestamp': 1612720783, 'time_this_iter_s': 5.5109031200408936, 'time_total_s': 122.10496163368225, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 122.10496163368225, 'timesteps_since_restore': 0, 'iterations_since_restore': 24, 'perf': {'cpu_util_percent': 63.07142857142857, 'ram_util_percent': 75.41428571428571}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3190, 'timers': {'grad_wait_time_ms': 443.532, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5278.311, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.29851007, 'policy_entropy': 2.874833, 'var_gnorm': 23.432104, 'vf_loss': 0.6771995, 'model': {}, 'grad_gnorm': 5.9219656, 'vf_explained_var': 0.08800906}}, 'num_steps_sampled': 3190, 'num_steps_trained': 3190}, 'done': False, 'episodes_total': 0, 'training_iteration': 25, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-49', 'timestamp': 1612720789, 'time_this_iter_s': 5.470732688903809, 'time_total_s': 127.57569432258606, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 127.57569432258606, 'timesteps_since_restore': 0, 'iterations_since_restore': 25, 'perf': {'cpu_util_percent': 46.849999999999994, 'ram_util_percent': 75.4625}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3290, 'timers': {'grad_wait_time_ms': 430.601, 'apply_grad_time_ms': 1.293, 'apply_grad_throughput': 7731.578, 'update_time_ms': 1.995}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.28187135, 'policy_entropy': 2.1339476, 'var_gnorm': 23.473654, 'vf_loss': 1.4834762, 'model': {}, 'grad_gnorm': 16.966324, 'vf_explained_var': 0.27156585}}, 'num_steps_sampled': 3290, 'num_steps_trained': 3290}, 'done': False, 'episodes_total': 0, 'training_iteration': 26, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_18-59-54', 'timestamp': 1612720794, 'time_this_iter_s': 5.349639415740967, 'time_total_s': 132.92533373832703, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 132.92533373832703, 'timesteps_since_restore': 0, 'iterations_since_restore': 26, 'perf': {'cpu_util_percent': 42.7375, 'ram_util_percent': 75.4375}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3400, 'timers': {'grad_wait_time_ms': 478.325, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5278.311, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.40214863, 'policy_entropy': 2.0470357, 'var_gnorm': 23.485668, 'vf_loss': 1.3494961, 'model': {}, 'grad_gnorm': 10.427281, 'vf_explained_var': 0.25793785}}, 'num_steps_sampled': 3400, 'num_steps_trained': 3400}, 'done': False, 'episodes_total': 0, 'training_iteration': 27, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-00', 'timestamp': 1612720800, 'time_this_iter_s': 5.87004280090332, 'time_total_s': 138.79537653923035, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 138.79537653923035, 'timesteps_since_restore': 0, 'iterations_since_restore': 27, 'perf': {'cpu_util_percent': 48.0125, 'ram_util_percent': 75.41250000000001}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3500, 'timers': {'grad_wait_time_ms': 396.098, 'apply_grad_time_ms': 2.294, 'apply_grad_throughput': 4359.213, 'update_time_ms': 2.493}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.022138398, 'policy_entropy': 0.9527101, 'var_gnorm': 23.478409, 'vf_loss': 0.43326545, 'model': {}, 'grad_gnorm': 5.921579, 'vf_explained_var': 0.3454852}}, 'num_steps_sampled': 3500, 'num_steps_trained': 3500}, 'done': False, 'episodes_total': 0, 'training_iteration': 28, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-05', 'timestamp': 1612720805, 'time_this_iter_s': 5.051492214202881, 'time_total_s': 143.84686875343323, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 143.84686875343323, 'timesteps_since_restore': 0, 'iterations_since_restore': 28, 'perf': {'cpu_util_percent': 55.957142857142856, 'ram_util_percent': 75.41428571428571}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3590, 'timers': {'grad_wait_time_ms': 470.874, 'apply_grad_time_ms': 2.095, 'apply_grad_throughput': 4774.284, 'update_time_ms': 2.593}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.05196523, 'policy_entropy': 1.0739025, 'var_gnorm': 23.474726, 'vf_loss': 0.9122875, 'model': {}, 'grad_gnorm': 19.483105, 'vf_explained_var': -0.24452066}}, 'num_steps_sampled': 3590, 'num_steps_trained': 3590}, 'done': False, 'episodes_total': 0, 'training_iteration': 29, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-11', 'timestamp': 1612720811, 'time_this_iter_s': 5.493541479110718, 'time_total_s': 149.34041023254395, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 149.34041023254395, 'timesteps_since_restore': 0, 'iterations_since_restore': 29, 'perf': {'cpu_util_percent': 62.25, 'ram_util_percent': 75.55000000000001}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3690, 'timers': {'grad_wait_time_ms': 461.864, 'apply_grad_time_ms': 2.194, 'apply_grad_throughput': 4557.936, 'update_time_ms': 2.493}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.008581941, 'policy_entropy': 0.5365244, 'var_gnorm': 23.45429, 'vf_loss': 0.14069326, 'model': {}, 'grad_gnorm': 3.2201028, 'vf_explained_var': 0.37925816}}, 'num_steps_sampled': 3690, 'num_steps_trained': 3690}, 'done': False, 'episodes_total': 0, 'training_iteration': 30, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-17', 'timestamp': 1612720817, 'time_this_iter_s': 5.980010509490967, 'time_total_s': 155.3204207420349, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 155.3204207420349, 'timesteps_since_restore': 0, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': 54.1625, 'ram_util_percent': 75.6625}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3790, 'timers': {'grad_wait_time_ms': 452.421, 'apply_grad_time_ms': 1.695, 'apply_grad_throughput': 5899.577, 'update_time_ms': 2.693}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.02807099, 'policy_entropy': 0.9244982, 'var_gnorm': 23.449486, 'vf_loss': 0.6506072, 'model': {}, 'grad_gnorm': 17.108343, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 3790, 'num_steps_trained': 3790}, 'done': False, 'episodes_total': 0, 'training_iteration': 31, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-22', 'timestamp': 1612720822, 'time_this_iter_s': 5.632554531097412, 'time_total_s': 160.95297527313232, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 160.95297527313232, 'timesteps_since_restore': 0, 'iterations_since_restore': 31, 'perf': {'cpu_util_percent': 49.5125, 'ram_util_percent': 75.5625}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3880, 'timers': {'grad_wait_time_ms': 507.607, 'apply_grad_time_ms': 1.795, 'apply_grad_throughput': 5571.457, 'update_time_ms': 2.693}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.5330564, 'policy_entropy': 0.6752775, 'var_gnorm': 23.449604, 'vf_loss': 0.6996468, 'model': {}, 'grad_gnorm': 4.666166, 'vf_explained_var': 0.06201482}}, 'num_steps_sampled': 3880, 'num_steps_trained': 3880}, 'done': False, 'episodes_total': 0, 'training_iteration': 32, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-27', 'timestamp': 1612720827, 'time_this_iter_s': 5.165181636810303, 'time_total_s': 166.11815690994263, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 166.11815690994263, 'timesteps_since_restore': 0, 'iterations_since_restore': 32, 'perf': {'cpu_util_percent': 57.7625, 'ram_util_percent': 75.6625}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 3970, 'timers': {'grad_wait_time_ms': 463.718, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5278.045, 'update_time_ms': 2.493}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.11432422, 'policy_entropy': 0.93393314, 'var_gnorm': 23.460485, 'vf_loss': 2.0892425, 'model': {}, 'grad_gnorm': 14.793607, 'vf_explained_var': -0.14535189}}, 'num_steps_sampled': 3970, 'num_steps_trained': 3970}, 'done': False, 'episodes_total': 0, 'training_iteration': 33, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-33', 'timestamp': 1612720833, 'time_this_iter_s': 5.3157854080200195, 'time_total_s': 171.43394231796265, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 171.43394231796265, 'timesteps_since_restore': 0, 'iterations_since_restore': 33, 'perf': {'cpu_util_percent': 45.42857142857144, 'ram_util_percent': 75.60000000000001}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4070, 'timers': {'grad_wait_time_ms': 421.892, 'apply_grad_time_ms': 2.294, 'apply_grad_throughput': 4359.983, 'update_time_ms': 2.593}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.005601608, 'policy_entropy': 0.4017539, 'var_gnorm': 23.458296, 'vf_loss': 0.151912, 'model': {}, 'grad_gnorm': 3.204725, 'vf_explained_var': -0.057780743}}, 'num_steps_sampled': 4070, 'num_steps_trained': 4070}, 'done': False, 'episodes_total': 0, 'training_iteration': 34, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-38', 'timestamp': 1612720838, 'time_this_iter_s': 5.391583442687988, 'time_total_s': 176.82552576065063, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 176.82552576065063, 'timesteps_since_restore': 0, 'iterations_since_restore': 34, 'perf': {'cpu_util_percent': 56.7, 'ram_util_percent': 75.6125}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4160, 'timers': {'grad_wait_time_ms': 477.216, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.411, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.24539468, 'policy_entropy': 1.10304, 'var_gnorm': 23.456154, 'vf_loss': 0.67015016, 'model': {}, 'grad_gnorm': 13.494499, 'vf_explained_var': -1.0}}, 'num_steps_sampled': 4160, 'num_steps_trained': 4160}, 'done': False, 'episodes_total': 0, 'training_iteration': 35, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-43', 'timestamp': 1612720843, 'time_this_iter_s': 5.042517185211182, 'time_total_s': 181.86804294586182, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 181.86804294586182, 'timesteps_since_restore': 0, 'iterations_since_restore': 35, 'perf': {'cpu_util_percent': 54.08571428571428, 'ram_util_percent': 75.64285714285715}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4260, 'timers': {'grad_wait_time_ms': 402.661, 'apply_grad_time_ms': 1.396, 'apply_grad_throughput': 7162.894, 'update_time_ms': 2.194}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.006156726, 'policy_entropy': 0.5043837, 'var_gnorm': 23.454062, 'vf_loss': 0.26104757, 'model': {}, 'grad_gnorm': 8.315699, 'vf_explained_var': -0.3844539}}, 'num_steps_sampled': 4260, 'num_steps_trained': 4260}, 'done': False, 'episodes_total': 0, 'training_iteration': 36, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-48', 'timestamp': 1612720848, 'time_this_iter_s': 5.149232387542725, 'time_total_s': 187.01727533340454, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 187.01727533340454, 'timesteps_since_restore': 0, 'iterations_since_restore': 36, 'perf': {'cpu_util_percent': 51.92857142857142, 'ram_util_percent': 75.64285714285714}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4350, 'timers': {'grad_wait_time_ms': 400.008, 'apply_grad_time_ms': 1.595, 'apply_grad_throughput': 6268.763, 'update_time_ms': 1.995}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.007097963, 'policy_entropy': 0.7979236, 'var_gnorm': 23.458698, 'vf_loss': 0.6471944, 'model': {}, 'grad_gnorm': 15.279278, 'vf_explained_var': -0.67795193}}, 'num_steps_sampled': 4350, 'num_steps_trained': 4350}, 'done': False, 'episodes_total': 0, 'training_iteration': 37, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-53', 'timestamp': 1612720853, 'time_this_iter_s': 4.958742141723633, 'time_total_s': 191.97601747512817, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 191.97601747512817, 'timesteps_since_restore': 0, 'iterations_since_restore': 37, 'perf': {'cpu_util_percent': 49.18571428571429, 'ram_util_percent': 75.67142857142856}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4440, 'timers': {'grad_wait_time_ms': 429.113, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5278.244, 'update_time_ms': 2.494}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.0005475539, 'policy_entropy': 0.30311555, 'var_gnorm': 23.457012, 'vf_loss': 0.11716546, 'model': {}, 'grad_gnorm': 4.3383923, 'vf_explained_var': -0.25830686}}, 'num_steps_sampled': 4440, 'num_steps_trained': 4440}, 'done': False, 'episodes_total': 0, 'training_iteration': 38, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-00-59', 'timestamp': 1612720859, 'time_this_iter_s': 5.172183513641357, 'time_total_s': 197.14820098876953, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 197.14820098876953, 'timesteps_since_restore': 0, 'iterations_since_restore': 38, 'perf': {'cpu_util_percent': 56.4125, 'ram_util_percent': 75.675}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4520, 'timers': {'grad_wait_time_ms': 488.838, 'apply_grad_time_ms': 2.094, 'apply_grad_throughput': 4775.697, 'update_time_ms': 2.493}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.013633374, 'policy_entropy': 0.6741906, 'var_gnorm': 23.455309, 'vf_loss': 0.58146226, 'model': {}, 'grad_gnorm': 13.13584, 'vf_explained_var': -0.6053268}}, 'num_steps_sampled': 4520, 'num_steps_trained': 4520}, 'done': False, 'episodes_total': 0, 'training_iteration': 39, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-04', 'timestamp': 1612720864, 'time_this_iter_s': 5.061466455459595, 'time_total_s': 202.20966744422913, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 202.20966744422913, 'timesteps_since_restore': 0, 'iterations_since_restore': 39, 'perf': {'cpu_util_percent': 58.84285714285715, 'ram_util_percent': 75.88571428571427}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4610, 'timers': {'grad_wait_time_ms': 459.819, 'apply_grad_time_ms': 1.995, 'apply_grad_throughput': 5013.512, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.005340565, 'policy_entropy': 0.38980234, 'var_gnorm': 23.45652, 'vf_loss': 0.14618815, 'model': {}, 'grad_gnorm': 7.1618686, 'vf_explained_var': 0.31929654}}, 'num_steps_sampled': 4610, 'num_steps_trained': 4610}, 'done': False, 'episodes_total': 0, 'training_iteration': 40, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-09', 'timestamp': 1612720869, 'time_this_iter_s': 5.612991094589233, 'time_total_s': 207.82265853881836, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 207.82265853881836, 'timesteps_since_restore': 0, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': 53.475, 'ram_util_percent': 75.91250000000001}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4700, 'timers': {'grad_wait_time_ms': 500.621, 'apply_grad_time_ms': 1.496, 'apply_grad_throughput': 6684.469, 'update_time_ms': 1.994}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.011914363, 'policy_entropy': 1.2857764, 'var_gnorm': 23.466291, 'vf_loss': 2.717346, 'model': {}, 'grad_gnorm': 17.160662, 'vf_explained_var': 0.106580675}}, 'num_steps_sampled': 4700, 'num_steps_trained': 4700}, 'done': False, 'episodes_total': 0, 'training_iteration': 41, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-15', 'timestamp': 1612720875, 'time_this_iter_s': 5.614995241165161, 'time_total_s': 213.43765377998352, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 213.43765377998352, 'timesteps_since_restore': 0, 'iterations_since_restore': 41, 'perf': {'cpu_util_percent': 45.3125, 'ram_util_percent': 75.91250000000001}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4800, 'timers': {'grad_wait_time_ms': 497.098, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.111, 'update_time_ms': 2.395}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.6928282, 'policy_entropy': 1.4582343, 'var_gnorm': 23.47591, 'vf_loss': 3.071538, 'model': {}, 'grad_gnorm': 12.7521715, 'vf_explained_var': 0.05356258}}, 'num_steps_sampled': 4800, 'num_steps_trained': 4800}, 'done': False, 'episodes_total': 0, 'training_iteration': 42, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-21', 'timestamp': 1612720881, 'time_this_iter_s': 6.481669187545776, 'time_total_s': 219.9193229675293, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 219.9193229675293, 'timesteps_since_restore': 0, 'iterations_since_restore': 42, 'perf': {'cpu_util_percent': 54.56666666666666, 'ram_util_percent': 76.04444444444445}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4890, 'timers': {'grad_wait_time_ms': 490.492, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5278.244, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.005305267, 'policy_entropy': 0.32613575, 'var_gnorm': 23.474733, 'vf_loss': 1.6217015, 'model': {}, 'grad_gnorm': 20.167515, 'vf_explained_var': 0.12737238}}, 'num_steps_sampled': 4890, 'num_steps_trained': 4890}, 'done': False, 'episodes_total': 0, 'training_iteration': 43, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-26', 'timestamp': 1612720886, 'time_this_iter_s': 4.90890097618103, 'time_total_s': 224.82822394371033, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 224.82822394371033, 'timesteps_since_restore': 0, 'iterations_since_restore': 43, 'perf': {'cpu_util_percent': 53.08571428571429, 'ram_util_percent': 76.11428571428571}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 4980, 'timers': {'grad_wait_time_ms': 475.849, 'apply_grad_time_ms': 1.695, 'apply_grad_throughput': 5899.245, 'update_time_ms': 2.195}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.001590929, 'policy_entropy': 0.25060207, 'var_gnorm': 23.471216, 'vf_loss': 0.3294231, 'model': {}, 'grad_gnorm': 7.2690563, 'vf_explained_var': -0.29554403}}, 'num_steps_sampled': 4980, 'num_steps_trained': 4980}, 'done': False, 'episodes_total': 0, 'training_iteration': 44, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-32', 'timestamp': 1612720892, 'time_this_iter_s': 5.497369289398193, 'time_total_s': 230.32559323310852, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 230.32559323310852, 'timesteps_since_restore': 0, 'iterations_since_restore': 44, 'perf': {'cpu_util_percent': 43.34285714285715, 'ram_util_percent': 75.91428571428571}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5070, 'timers': {'grad_wait_time_ms': 495.94, 'apply_grad_time_ms': 1.695, 'apply_grad_throughput': 5898.249, 'update_time_ms': 2.095}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.63957113, 'policy_entropy': 0.84973544, 'var_gnorm': 23.459967, 'vf_loss': 3.3554482, 'model': {}, 'grad_gnorm': 25.75937, 'vf_explained_var': 0.24217343}}, 'num_steps_sampled': 5070, 'num_steps_trained': 5070}, 'done': False, 'episodes_total': 0, 'training_iteration': 45, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-37', 'timestamp': 1612720897, 'time_this_iter_s': 5.351690292358398, 'time_total_s': 235.67728352546692, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 235.67728352546692, 'timesteps_since_restore': 0, 'iterations_since_restore': 45, 'perf': {'cpu_util_percent': 45.925, 'ram_util_percent': 75.5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5160, 'timers': {'grad_wait_time_ms': 497.712, 'apply_grad_time_ms': 1.695, 'apply_grad_throughput': 5898.913, 'update_time_ms': 2.094}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': 0.007449736, 'policy_entropy': 1.1140811, 'var_gnorm': 23.460312, 'vf_loss': 0.5807463, 'model': {}, 'grad_gnorm': 11.102607, 'vf_explained_var': 0.0012685657}}, 'num_steps_sampled': 5160, 'num_steps_trained': 5160}, 'done': False, 'episodes_total': 0, 'training_iteration': 46, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-43', 'timestamp': 1612720903, 'time_this_iter_s': 5.381610631942749, 'time_total_s': 241.05889415740967, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 241.05889415740967, 'timesteps_since_restore': 0, 'iterations_since_restore': 46, 'perf': {'cpu_util_percent': 53.1625, 'ram_util_percent': 75.5375}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5260, 'timers': {'grad_wait_time_ms': 410.325, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5013.811, 'update_time_ms': 2.396}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.4645901, 'policy_entropy': 3.3221025, 'var_gnorm': 23.472044, 'vf_loss': 0.31221855, 'model': {}, 'grad_gnorm': 8.358947, 'vf_explained_var': -0.5735949}}, 'num_steps_sampled': 5260, 'num_steps_trained': 5260}, 'done': False, 'episodes_total': 0, 'training_iteration': 47, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-48', 'timestamp': 1612720908, 'time_this_iter_s': 5.252955198287964, 'time_total_s': 246.31184935569763, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 246.31184935569763, 'timesteps_since_restore': 0, 'iterations_since_restore': 47, 'perf': {'cpu_util_percent': 51.614285714285714, 'ram_util_percent': 75.5}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5360, 'timers': {'grad_wait_time_ms': 467.374, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.111, 'update_time_ms': 2.593}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -1.1333494, 'policy_entropy': 6.762304, 'var_gnorm': 23.53883, 'vf_loss': 1.1831713, 'model': {}, 'grad_gnorm': 18.681828, 'vf_explained_var': 0.13002211}}, 'num_steps_sampled': 5360, 'num_steps_trained': 5360}, 'done': False, 'episodes_total': 0, 'training_iteration': 48, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-54', 'timestamp': 1612720914, 'time_this_iter_s': 5.915182828903198, 'time_total_s': 252.22703218460083, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 252.22703218460083, 'timesteps_since_restore': 0, 'iterations_since_restore': 48, 'perf': {'cpu_util_percent': 50.55, 'ram_util_percent': 75.525}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5450, 'timers': {'grad_wait_time_ms': 508.302, 'apply_grad_time_ms': 1.695, 'apply_grad_throughput': 5899.494, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -7.04278, 'policy_entropy': 4.705945, 'var_gnorm': 23.71747, 'vf_loss': 58.7892, 'model': {}, 'grad_gnorm': 39.999996, 'vf_explained_var': 0.09827757}}, 'num_steps_sampled': 5450, 'num_steps_trained': 5450}, 'done': False, 'episodes_total': 0, 'training_iteration': 49, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-01-59', 'timestamp': 1612720919, 'time_this_iter_s': 5.500293016433716, 'time_total_s': 257.72732520103455, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 257.72732520103455, 'timesteps_since_restore': 0, 'iterations_since_restore': 49, 'perf': {'cpu_util_percent': 59.1125, 'ram_util_percent': 75.6125}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5540, 'timers': {'grad_wait_time_ms': 432.747, 'apply_grad_time_ms': 2.094, 'apply_grad_throughput': 4775.48, 'update_time_ms': 2.394}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.028920583, 'policy_entropy': 0.091041304, 'var_gnorm': 24.104652, 'vf_loss': 142.06606, 'model': {}, 'grad_gnorm': 40.000004, 'vf_explained_var': 0.1420263}}, 'num_steps_sampled': 5540, 'num_steps_trained': 5540}, 'done': False, 'episodes_total': 0, 'training_iteration': 50, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-05', 'timestamp': 1612720925, 'time_this_iter_s': 5.262927293777466, 'time_total_s': 262.990252494812, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 262.990252494812, 'timesteps_since_restore': 0, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': 60.237500000000004, 'ram_util_percent': 76.775}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-07 19:02:06,156\tWARNING worker.py:1034 -- The dashboard on node DESKTOP-3VKGC6T failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\new_dashboard\\dashboard.py\", line 187, in <module>\n",
      "    dashboard = Dashboard(\n",
      "  File \"C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\new_dashboard\\dashboard.py\", line 81, in __init__\n",
      "    build_dir = setup_static_dir()\n",
      "  File \"C:\\Users\\tobia\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ray\\new_dashboard\\dashboard.py\", line 38, in setup_static_dir\n",
      "    raise OSError(\n",
      "FileNotFoundError: [Errno 2] Dashboard build directory not found. If installing from source, please follow the additional steps required to build the dashboard(cd python/ray/new_dashboard/client && npm install && npm ci && npm run build): 'C:\\\\Users\\\\tobia\\\\anaconda3\\\\envs\\\\gpu_test\\\\lib\\\\site-packages\\\\ray\\\\new_dashboard\\\\client\\\\build'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5650, 'timers': {'grad_wait_time_ms': 433.115, 'apply_grad_time_ms': 2.393, 'apply_grad_throughput': 4178.259, 'update_time_ms': 2.594}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.0005432622, 'policy_entropy': 0.0038003286, 'var_gnorm': 24.771551, 'vf_loss': 52.531906, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': 0.27878124}}, 'num_steps_sampled': 5650, 'num_steps_trained': 5650}, 'done': False, 'episodes_total': 0, 'training_iteration': 51, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-10', 'timestamp': 1612720930, 'time_this_iter_s': 5.204084634780884, 'time_total_s': 268.1943371295929, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 268.1943371295929, 'timesteps_since_restore': 0, 'iterations_since_restore': 51, 'perf': {'cpu_util_percent': 55.41428571428571, 'ram_util_percent': 77.47142857142856}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,267 C 20484 20308] redis_client.cc:74:  Check failed: num_attempts < RayConfig::instance().redis_db_connect_retries() Expected 1 Redis shard addresses, found 2\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,268 E 20484 20308] logging.cc:414: *** Aborted at 1612720930 (unix time) try \"date -d @1612720930\" if you are using GNU date ***\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,273 E 20484 20308] logging.cc:414:     @     0x7fff3be81881 raise\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,273 E 20484 20308] logging.cc:414:     @     0x7fff3be82851 abort\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff625e48d7b public: void __cdecl google::NullStreamFatal::`vbase destructor'(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff625e476b1 public: virtual __cdecl google::NullStreamFatal::~NullStreamFatal(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff625d78194 public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff625d772d7 public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff625d76d24 public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff625d7320c public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff625cb4245 public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff625c6cd0b public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,274 E 20484 20308] logging.cc:414:     @     0x7ff626108760 bool __cdecl google::Demangle(char const * __ptr64,char * __ptr64,int)\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,275 E 20484 20308] logging.cc:414:     @     0x7fff3c0e7034 BaseThreadInitThunk\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,277 E 20484 20308] logging.cc:414:     @     0x7fff3defd241 RtlUserThreadStart\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,536 C 6236 20988] redis_client.cc:74:  Check failed: num_attempts < RayConfig::instance().redis_db_connect_retries() Expected 1 Redis shard addresses, found 2\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,537 E 6236 20988] logging.cc:414: *** Aborted at 1612720930 (unix time) try \"date -d @1612720930\" if you are using GNU date ***\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,540 E 6236 20988] logging.cc:414:     @     0x7fff3be81881 raise\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,540 E 6236 20988] logging.cc:414:     @     0x7fff3be82851 abort\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,541 E 6236 20988] logging.cc:414:     @     0x7ff6e308941b public: void __cdecl google::NullStreamFatal::`vbase destructor'(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,541 E 6236 20988] logging.cc:414:     @     0x7ff6e3087dd1 public: virtual __cdecl google::NullStreamFatal::~NullStreamFatal(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,541 E 6236 20988] logging.cc:414:     @     0x7ff6e2f52ef4 public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,541 E 6236 20988] logging.cc:414:     @     0x7ff6e2f52037 public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,542 E 6236 20988] logging.cc:414:     @     0x7ff6e2f51a84 public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,542 E 6236 20988] logging.cc:414:     @     0x7ff6e2f48c2c public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,542 E 6236 20988] logging.cc:414:     @     0x7ff6e2f00397 public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,542 E 6236 20988] logging.cc:414:     @     0x7ff6e2deae90 public: class google::NullStream & __ptr64 __cdecl google::NullStream::stream(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,542 E 6236 20988] logging.cc:414:     @     0x7ff6e3376fa0 bool __cdecl google::Demangle(char const * __ptr64,char * __ptr64,int)\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,543 E 6236 20988] logging.cc:414:     @     0x7fff3c0e7034 BaseThreadInitThunk\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m [2021-02-07 19:02:10,545 E 6236 20988] logging.cc:414:     @     0x7fff3defd241 RtlUserThreadStart\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5760, 'timers': {'grad_wait_time_ms': 412.842, 'apply_grad_time_ms': 2.393, 'apply_grad_throughput': 4178.509, 'update_time_ms': 2.693}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.0001767735, 'policy_entropy': 0.0013080977, 'var_gnorm': 25.157108, 'vf_loss': 48.0344, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': 0.21888071}}, 'num_steps_sampled': 5760, 'num_steps_trained': 5760}, 'done': False, 'episodes_total': 0, 'training_iteration': 52, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-15', 'timestamp': 1612720935, 'time_this_iter_s': 5.032543659210205, 'time_total_s': 273.2268807888031, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 273.2268807888031, 'timesteps_since_restore': 0, 'iterations_since_restore': 52, 'perf': {'cpu_util_percent': 54.728571428571435, 'ram_util_percent': 77.44285714285715}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5870, 'timers': {'grad_wait_time_ms': 412.303, 'apply_grad_time_ms': 2.094, 'apply_grad_throughput': 4774.828, 'update_time_ms': 2.593}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.00013353405, 'policy_entropy': 0.0010118827, 'var_gnorm': 25.383524, 'vf_loss': 44.181015, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': 0.19580019}}, 'num_steps_sampled': 5870, 'num_steps_trained': 5870}, 'done': False, 'episodes_total': 0, 'training_iteration': 53, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-20', 'timestamp': 1612720940, 'time_this_iter_s': 5.227022409439087, 'time_total_s': 278.4539031982422, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 278.4539031982422, 'timesteps_since_restore': 0, 'iterations_since_restore': 53, 'perf': {'cpu_util_percent': 52.9875, 'ram_util_percent': 77.33749999999999}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 5980, 'timers': {'grad_wait_time_ms': 433.742, 'apply_grad_time_ms': 1.895, 'apply_grad_throughput': 5277.646, 'update_time_ms': 2.693}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.00018494316, 'policy_entropy': 0.0011630075, 'var_gnorm': 25.538254, 'vf_loss': 91.56179, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': 0.109766126}}, 'num_steps_sampled': 5980, 'num_steps_trained': 5980}, 'done': False, 'episodes_total': 0, 'training_iteration': 54, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-26', 'timestamp': 1612720946, 'time_this_iter_s': 5.498685359954834, 'time_total_s': 283.952588558197, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 283.952588558197, 'timesteps_since_restore': 0, 'iterations_since_restore': 54, 'perf': {'cpu_util_percent': 61.528571428571425, 'ram_util_percent': 77.42857142857143}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 6090, 'timers': {'grad_wait_time_ms': 428.054, 'apply_grad_time_ms': 1.795, 'apply_grad_throughput': 5570.643, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.00012917447, 'policy_entropy': 0.0010639918, 'var_gnorm': 25.68656, 'vf_loss': 36.350395, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': 0.16947466}}, 'num_steps_sampled': 6090, 'num_steps_trained': 6090}, 'done': False, 'episodes_total': 0, 'training_iteration': 55, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-31', 'timestamp': 1612720951, 'time_this_iter_s': 5.196114778518677, 'time_total_s': 289.1487033367157, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 289.1487033367157, 'timesteps_since_restore': 0, 'iterations_since_restore': 55, 'perf': {'cpu_util_percent': 58.45, 'ram_util_percent': 77.6625}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 6210, 'timers': {'grad_wait_time_ms': 457.442, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5013.871, 'update_time_ms': 2.194}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.00020415045, 'policy_entropy': 0.0012894642, 'var_gnorm': 25.788792, 'vf_loss': 76.17284, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': 0.09983075}}, 'num_steps_sampled': 6210, 'num_steps_trained': 6210}, 'done': False, 'episodes_total': 0, 'training_iteration': 56, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-36', 'timestamp': 1612720956, 'time_this_iter_s': 5.681807518005371, 'time_total_s': 294.83051085472107, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 294.83051085472107, 'timesteps_since_restore': 0, 'iterations_since_restore': 56, 'perf': {'cpu_util_percent': 52.412499999999994, 'ram_util_percent': 77.575}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 6320, 'timers': {'grad_wait_time_ms': 421.545, 'apply_grad_time_ms': 1.695, 'apply_grad_throughput': 5899.494, 'update_time_ms': 2.593}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.000118502074, 'policy_entropy': 0.0011118369, 'var_gnorm': 25.888037, 'vf_loss': 29.861748, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': 0.16492283}}, 'num_steps_sampled': 6320, 'num_steps_trained': 6320}, 'done': False, 'episodes_total': 0, 'training_iteration': 57, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-42', 'timestamp': 1612720962, 'time_this_iter_s': 5.129286527633667, 'time_total_s': 299.95979738235474, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 299.95979738235474, 'timesteps_since_restore': 0, 'iterations_since_restore': 57, 'perf': {'cpu_util_percent': 56.9, 'ram_util_percent': 76.77142857142859}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 6440, 'timers': {'grad_wait_time_ms': 474.617, 'apply_grad_time_ms': 1.994, 'apply_grad_throughput': 5014.591, 'update_time_ms': 2.494}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.00018542306, 'policy_entropy': 0.0013054938, 'var_gnorm': 25.972397, 'vf_loss': 63.864964, 'model': {}, 'grad_gnorm': 40.000004, 'vf_explained_var': 0.10252762}}, 'num_steps_sampled': 6440, 'num_steps_trained': 6440}, 'done': False, 'episodes_total': 0, 'training_iteration': 58, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-47', 'timestamp': 1612720967, 'time_this_iter_s': 5.835395574569702, 'time_total_s': 305.79519295692444, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 305.79519295692444, 'timesteps_since_restore': 0, 'iterations_since_restore': 58, 'perf': {'cpu_util_percent': 56.3625, 'ram_util_percent': 76.525}}\n",
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 6550, 'timers': {'grad_wait_time_ms': 403.571, 'apply_grad_time_ms': 2.194, 'apply_grad_throughput': 4558.035, 'update_time_ms': 2.393}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.00010433479, 'policy_entropy': 0.0011027954, 'var_gnorm': 26.059153, 'vf_loss': 24.563927, 'model': {}, 'grad_gnorm': 40.0, 'vf_explained_var': 0.15365446}}, 'num_steps_sampled': 6550, 'num_steps_trained': 6550}, 'done': False, 'episodes_total': 0, 'training_iteration': 59, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-52', 'timestamp': 1612720972, 'time_this_iter_s': 4.89997124671936, 'time_total_s': 310.6951642036438, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 310.6951642036438, 'timesteps_since_restore': 0, 'iterations_since_restore': 59, 'perf': {'cpu_util_percent': 50.37142857142857, 'ram_util_percent': 76.54285714285716}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'off_policy_estimator': {}, 'num_healthy_workers': 2, 'timesteps_total': 6670, 'timers': {'grad_wait_time_ms': 484.676, 'apply_grad_time_ms': 1.595, 'apply_grad_throughput': 6269.044, 'update_time_ms': 2.294}, 'info': {'learner': {'0': {'cur_lr': 0.0010000000474974513, 'policy_loss': -0.00016676157, 'policy_entropy': 0.0012973953, 'var_gnorm': 26.134542, 'vf_loss': 53.442547, 'model': {}, 'grad_gnorm': 40.000004, 'vf_explained_var': 0.100373745}}, 'num_steps_sampled': 6670, 'num_steps_trained': 6670}, 'done': False, 'episodes_total': 0, 'training_iteration': 60, 'experiment_id': '07f404d21678496fa4d62bc81821da96', 'date': '2021-02-07_19-02-58', 'timestamp': 1612720978, 'time_this_iter_s': 5.940772771835327, 'time_total_s': 316.6359369754791, 'pid': 19608, 'hostname': 'DESKTOP-3VKGC6T', 'node_ip': '192.168.0.168', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 10, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 200, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': True, 'env_config': {}, 'env': '4x4grid', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': True, '_use_trajectory_view_api': True, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 5, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'0': (<class 'ray.rllib.policy.tf_policy_template.A3CTFPolicy'>, Box(0.0, 1.0, (10,), float32), Discrete(2), {})}, 'policy_mapping_fn': <function <lambda> at 0x00000254E6E1DCA0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'grad_clip': 40.0, 'lr_schedule': None, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01}, 'time_since_restore': 316.6359369754791, 'timesteps_since_restore': 0, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': 51.07777777777778, 'ram_util_percent': 76.43333333333334}}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray.rllib.agents.a3c.a3c import A3CTrainer\n",
    "from ray.rllib.agents.a3c.a3c_tf_policy import A3CTFPolicy\n",
    "from ray.tune.registry import register_env\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from sumo_rl import SumoEnvironment\n",
    "import traci\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ray.init()\n",
    "\n",
    "    register_env(\"4x4grid\", lambda _: SumoEnvironment(net_file='nets/4x4-Lucas/4x4.net.xml',\n",
    "                                                    route_file='nets/4x4-Lucas/4x4c1c2c1c2.rou.xml',\n",
    "                                                    out_csv_name='outputs/4x4grid/a3c',\n",
    "                                                    use_gui=False,\n",
    "                                                    num_seconds=80000,\n",
    "                                                    max_depart_delay=0))\n",
    "\n",
    "    trainer = A3CTrainer(env=\"4x4grid\", config={\n",
    "        \"multiagent\": {\n",
    "            \"policies\": {\n",
    "                '0': (A3CTFPolicy, spaces.Box(low=np.zeros(10), high=np.ones(10)), spaces.Discrete(2), {})\n",
    "            },\n",
    "            \"policy_mapping_fn\": (lambda id: '0')  # Traffic lights are always controlled by this policy\n",
    "        },\n",
    "        \"lr\": 0.001,\n",
    "        \"no_done_at_end\": True\n",
    "    })\n",
    "    while True:\n",
    "        print(trainer.train())  # distributed training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
